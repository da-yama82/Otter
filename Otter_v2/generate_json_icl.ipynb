{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# icl_simple_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ○○_instructions.jsonの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_folder = \"/data/dataset/yyama_dataset/tasks/VI_ICL/simple\"  # jsonファイルを保存するベースフォルダのパス\n",
    "os.makedirs(base_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# コンテキストのフォルダを先に実行すること\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"\n",
    "    ファイル名の数字部分を考慮してソートするためのキー関数\n",
    "    \"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "def generate_json_from_directory(directory_path, output_json_path): # コンテキスト用\n",
    "    output = {\"data\": {}}\n",
    "    i = 0\n",
    "    # メインディレクトリ内のサブディレクトリを走査\n",
    "    for main_folder in os.listdir(directory_path):\n",
    "        main_folder_path = os.path.join(directory_path, main_folder)\n",
    "        \n",
    "        # サブディレクトリがディレクトリであるかの確認\n",
    "        if os.path.isdir(main_folder_path):\n",
    "            \n",
    "            # サブディレクトリ内のサブディレクトリを走査\n",
    "            for sub_folder in os.listdir(main_folder_path):\n",
    "                sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "                \n",
    "                # サブディレクトリ内のファイルを昇順に走査\n",
    "                for image_file in sorted(os.listdir(sub_folder_path), key=natural_sort_key):\n",
    "                    # 画像ファイルの拡張子を除去\n",
    "                    image_name_without_extension = os.path.splitext(image_file)[0]\n",
    "                    \n",
    "                    # キーの名前を生成\n",
    "                    key_name = f\"{main_folder}+{sub_folder}+{image_name_without_extension}\"\n",
    "                    \n",
    "                    # JSONのデータ構造を生成\n",
    "                    output[\"data\"][key_name] = {\n",
    "                        \"instruction\": \"\",\n",
    "                        \"answer\": \"\",\n",
    "                        \"flag\": \"context\",\n",
    "                        \"image_ids\": [key_name],\n",
    "                        \"rel_ok_ins_ids\": [],\n",
    "                        \"rel_ng_ins_ids\": [],\n",
    "                        \"label\": i\n",
    "                    }\n",
    "                i += 1\n",
    "    \n",
    "    # JSONをファイルに書き出し\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(output, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "context_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\"\n",
    "generate_json_from_directory(context_path, output_json_path)\n",
    "\n",
    "output_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "context_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\"\n",
    "generate_json_from_directory(context_path, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "# コンテキストのフォルダを実行した後に実行すること\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"\n",
    "    ファイル名の数字部分を考慮してソートするためのキー関数\n",
    "    \"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "def generate_and_merge_json_from_directory(directory_path, old_json_path, NUM): #クエリ用\n",
    "    # 以前のJSONを読み込む\n",
    "    with open(old_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        old_data = json.load(f)\n",
    "\n",
    "    new_data = {\"data\": {}}\n",
    "    i = 0\n",
    "    # メインディレクトリ内のサブディレクトリを走査\n",
    "    for main_folder in os.listdir(directory_path):\n",
    "        main_folder_path = os.path.join(directory_path, main_folder)\n",
    "\n",
    "        # サブディレクトリがディレクトリであるかの確認\n",
    "        if os.path.isdir(main_folder_path):\n",
    "\n",
    "            # サブディレクトリ内のサブディレクトリを走査\n",
    "            for sub_folder in os.listdir(main_folder_path):\n",
    "                sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "\n",
    "                # サブディレクトリ内のファイルを昇順に走査\n",
    "                for image_file in sorted(os.listdir(sub_folder_path), key=natural_sort_key):\n",
    "                    # 画像ファイルの拡張子を除去\n",
    "                    image_name_without_extension = os.path.splitext(image_file)[0]\n",
    "\n",
    "                    # キーの名前を生成\n",
    "                    key_name = f\"{main_folder}+{sub_folder}+{image_name_without_extension}\"\n",
    "\n",
    "                    # rel_ok_ins_idsの値を取得\n",
    "                    \"\"\"以下どちらか選択\"\"\"\n",
    "                    related_ok_keys = [key for key in old_data[\"data\"].keys() if key.startswith(f\"{main_folder}+None\")] # \"欠陥\"の場合\n",
    "                    # related_ok_keys = [key for key in old_data[\"data\"].keys() if key.startswith(f\"{main_folder}+{main_folder}+\")] # \"製品+欠陥\"の場合\n",
    "                    rel_ok_ins_ids = random.sample(related_ok_keys, min(NUM, len(related_ok_keys)))\n",
    "\n",
    "                    # rel_ng_ins_idsの値を取得\n",
    "                    \"\"\"以下どちらか選択\"\"\"\n",
    "                    if sub_folder == \"None\": # \"欠陥\"の場合\n",
    "                    # if main_folder==sub_folder: # \"製品+欠陥\"の場合\n",
    "                        \"\"\"以下どちらか選択\"\"\"\n",
    "                        related_ng_keys = [key for key in old_data[\"data\"].keys() if key.startswith(f\"{main_folder}+\") and not key.startswith(f\"{main_folder}+None\")] # \"欠陥\"の場合\n",
    "                        # related_ng_keys = [key for key in old_data[\"data\"].keys() if key.startswith(f\"{main_folder}+\") and not key.startswith(f\"{main_folder}+{main_folder}+\")] # \"製品+欠陥\"の場合\n",
    "                        related_ng_key_lists = {}\n",
    "                        for key in related_ng_keys:\n",
    "                            prefix = key.split('+')[1]\n",
    "                            if prefix not in related_ng_key_lists:\n",
    "                                related_ng_key_lists[prefix] = []\n",
    "                            related_ng_key_lists[prefix].append(key)\n",
    "\n",
    "                        rel_ng_ins_ids = []\n",
    "                        while len(rel_ng_ins_ids) < NUM and related_ng_key_lists:\n",
    "                            for prefix in list(related_ng_key_lists.keys()):\n",
    "                                if related_ng_key_lists[prefix]:\n",
    "                                    selected_key = random.choice(related_ng_key_lists[prefix])\n",
    "                                    rel_ng_ins_ids.append(selected_key)\n",
    "                                    related_ng_key_lists[prefix].remove(selected_key)\n",
    "                                else:\n",
    "                                    del related_ng_key_lists[prefix]\n",
    "                    else: # 不良品の場合\n",
    "                        related_ng_keys = [key for key in old_data[\"data\"].keys() if key.startswith(f\"{main_folder}+{sub_folder}+\")]\n",
    "                        rel_ng_ins_ids = random.sample(related_ng_keys, min(NUM, len(related_ng_keys)))\n",
    "\n",
    "                    # JSONのデータ構造を生成\n",
    "                    new_data[\"data\"][key_name] = {\n",
    "                        \"instruction\": \"\",\n",
    "                        \"answer\": \"\",\n",
    "                        \"flag\": \"query\",\n",
    "                        \"image_ids\": [key_name],\n",
    "                        \"rel_ok_ins_ids\": rel_ok_ins_ids,\n",
    "                        \"rel_ng_ins_ids\": rel_ng_ins_ids,\n",
    "                        \"label\": i\n",
    "                    }\n",
    "                i += 1\n",
    "\n",
    "    # 既存のJSONデータに新しいデータをマージ\n",
    "    old_data[\"data\"].update(new_data[\"data\"])\n",
    "\n",
    "    # JSONをファイルに書き出し\n",
    "    # old_json_path = \"output.json\"\n",
    "    with open(old_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(old_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "query_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_query\"\n",
    "NUM = 5 # 良品、不良品をそれぞれ5枚ずつ選ぶ\n",
    "generate_and_merge_json_from_directory(query_path, output_json_path, NUM)\n",
    "\n",
    "output_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "query_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_query\"\n",
    "NUM = 5 # 良品、不良品をそれぞれ5枚ずつ選ぶ\n",
    "generate_and_merge_json_from_directory(query_path, output_json_path, NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "context: 7165\n",
      "query: 7678\n",
      "val\n",
      "context: 1292\n",
      "query: 1556\n"
     ]
    }
   ],
   "source": [
    "# 数の確認\n",
    "def count_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "        \n",
    "    entries = [item for item in data.values() if item[\"flag\"] == \"context\"]\n",
    "    count = len(entries)\n",
    "    print(f\"context: {count}\")\n",
    "        \n",
    "    entries = [item for item in data.values() if item[\"flag\"] == \"query\"]\n",
    "    count = len(entries)\n",
    "    print(f\"query: {count}\")\n",
    "\n",
    "print(\"train\")\n",
    "json_path = f\"{base_folder}/train_instructions.json\"\n",
    "count_data(json_path)\n",
    "\n",
    "print(\"val\")\n",
    "json_path = f\"{base_folder}/val_instructions.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructionとanswerを埋める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_lines = [\n",
    "    \"In this image featuring a {product}, can you identify any issues?\",\n",
    "]\n",
    "\n",
    "yes_responses_array = [\n",
    "    \"Yes. This {product} has {defect}, indicating an issue.\",\n",
    "]\n",
    "\n",
    "no_responses_array = [\n",
    "    \"No. This photograph of the {product} does not exhibit any signs. It appears to be non-defective.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定されたリスト形式の文字列を作成する関数\n",
    "def generate_list_string(items):\n",
    "    # アンダースコアをスペースに変換\n",
    "    items = [item.replace('_', ' ') for item in items]\n",
    "    \n",
    "    if len(items) == 1:\n",
    "        return items[0]\n",
    "    elif len(items) == 2:\n",
    "        return f\"{items[0]} and {items[1]}\"\n",
    "    else:\n",
    "        return \", \".join(items[:-1]) + f\", and {items[-1]}\"\n",
    "\n",
    "def fill_instruction_and_answer(json_path, train_context_dir):\n",
    "    # JSONを読み込む\n",
    "    random_list = np.zeros(len(question_lines))\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    # ['data']からキーを順に読み込む\n",
    "    for key, value in data.items():\n",
    "        # キーの名前から親フォルダ名と子フォルダ名を認識する\n",
    "        parent_folder, child_folder, _ = key.split(\"+\")\n",
    "\n",
    "        # \"./1_train_context/親フォルダ名\"にアクセスし、その中にある子フォルダ名をリスト化する\n",
    "        subfolder_list = os.listdir(os.path.join(train_context_dir, parent_folder))\n",
    "        subfolder_list = [folder for folder in subfolder_list if folder != \"None\"] # 欠陥名のみリスト化\n",
    "\n",
    "        # \"instruction\"にテキストを入力する\n",
    "        parent_folder__ = parent_folder.replace('_', ' ')\n",
    "        # long\n",
    "        random_idx = random.randint(0, len(question_lines)-1)\n",
    "        random_list[random_idx] += 1\n",
    "        value[\"instruction\"] = question_lines[random_idx].format(product=parent_folder__, defect=child_folder)\n",
    "        \n",
    "        # \"answer\"にテキストを入力する\n",
    "        if child_folder == \"None\": # \"欠陥\"の場合\n",
    "        # if child_folder == parent_folder: # \"製品+欠陥\"の場合\n",
    "            value[\"answer\"] = no_responses_array[random_idx].format(product=parent_folder, defect=child_folder)\n",
    "        else:\n",
    "            child_folder = child_folder.replace('_', ' ')\n",
    "            value[\"answer\"] = yes_responses_array[random_idx].format(product=parent_folder, defect=child_folder)\n",
    "\n",
    "    # JSONをファイルに書き出し\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump({\"data\": data}, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "train_context_dir = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\" # コンテキストのみでok (クエリと同じフォルダ構成のため)\n",
    "fill_instruction_and_answer(output_json_path, train_context_dir)\n",
    "\n",
    "output_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "train_context_dir = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\" # コンテキストのみでok (クエリと同じフォルダ構成のため)\n",
    "fill_instruction_and_answer(output_json_path, train_context_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ○○_train.jsonの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def create_visual_inspection_train(input_json_path, output_json_path, NUM_PAIRS):\n",
    "    # JSONを読み込む\n",
    "    with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    train_data = {}\n",
    "\n",
    "    # ['data']からキーを順に読み込む\n",
    "    for key, value in data.items():\n",
    "        # 'flag'=='query'のキーを選択\n",
    "        if value[\"flag\"] == \"query\":\n",
    "            # \"rel_ok_ins_ids\"と\"rel_ng_ins_ids\"を読み込み\n",
    "            ok_ids = value[\"rel_ok_ins_ids\"]\n",
    "            ng_ids = value[\"rel_ng_ins_ids\"]\n",
    "\n",
    "            # すべての組み合わせをリストに保存\n",
    "            combinations = []\n",
    "            for ok_id in ok_ids:\n",
    "                for ng_id in ng_ids:\n",
    "                    combinations.append([ok_id, ng_id])\n",
    "\n",
    "            # リスト内の各組内の要素をランダムにシャッフル\n",
    "            for combination in combinations:\n",
    "                random.shuffle(combination)\n",
    "\n",
    "            # キー名を更新してデータを保存\n",
    "            random.shuffle(combinations)\n",
    "            for i, combination in enumerate(combinations[:NUM_PAIRS]):\n",
    "                train_data[f\"{key}={i}\"] = combination\n",
    "\n",
    "    # JSONをファイルに書き出し\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(train_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "NUM_PAIRS = 25 # 1つのクエリに対して生成する組み合わせの数\n",
    "input_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/train_pairs{NUM_PAIRS}_train.json\"\n",
    "create_visual_inspection_train(input_json_path, output_json_path, NUM_PAIRS)\n",
    "\n",
    "NUM_PAIRS__ = 1 # 1つのクエリに対して生成する組み合わせの数（valは1にするとクエリが一回のみ）\n",
    "input_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/val_pairs{NUM_PAIRS__}_train.json\"\n",
    "create_visual_inspection_train(input_json_path, output_json_path, NUM_PAIRS__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "ペア数: 138963\n",
      "クエリ良品: 78071\n",
      "クエリ不良品: 60892\n",
      "val\n",
      "ペア数: 1556\n",
      "クエリ良品: 733\n",
      "クエリ不良品: 823\n"
     ]
    }
   ],
   "source": [
    "# 数の確認\n",
    "def count_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    count = len(data.keys())\n",
    "    print(f\"ペア数: {count}\")\n",
    "    oks = [key for key in data.keys() if key.split(\"+\")[1] == \"None\"] # \"欠陥\"の場合\n",
    "    # oks = [key for key in data.keys() if key.split(\"+\")[0] == key.split(\"+\")[1]] # \"製品+欠陥\"の場合\n",
    "    print(f\"クエリ良品: {len(oks)}\")\n",
    "    ngs = [key for key in data.keys() if key.split(\"+\")[1] != \"None\"] # \"欠陥\"の場合\n",
    "    # ngs = [key for key in data.keys() if key.split(\"+\")[0] != key.split(\"+\")[1]] # \"製品+欠陥\"の場合\n",
    "    print(f\"クエリ不良品: {len(ngs)}\")\n",
    "    \n",
    "print(\"train\")\n",
    "# NUM_PAIRS = 25\n",
    "json_path = f\"{base_folder}/train_pairs{NUM_PAIRS}_train.json\"\n",
    "count_data(json_path)\n",
    "\n",
    "print(\"val\")\n",
    "# NUM_PAIRS__ = 1\n",
    "json_path = f\"{base_folder}/val_pairs{NUM_PAIRS__}_train.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ○○.jsonの作成（共通）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# コンテキスト　→　クエリの順で実行すること\n",
    "\n",
    "def image_to_urlsafe_base64_png(img_path):\n",
    "    \"\"\"画像をメモリ上でPNGに変換し、その後URL-safeなBase64に変換する関数\"\"\"\n",
    "    with Image.open(img_path) as image:\n",
    "        # CMYKモードの画像をRGBモードに変換\n",
    "        if image.mode == 'CMYK':\n",
    "            image = image.convert('RGB')\n",
    "        # パレットモードの画像をRGBAモードに変換\n",
    "        if image.mode == 'P':\n",
    "            image = image.convert('RGBA')\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        img_str = base64.urlsafe_b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    return img_str\n",
    "\n",
    "def create_visual_inspection(input_json_path, base_folder, output_json_path):\n",
    "    # JSONを読み込む\n",
    "    with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    # 既存のvisual_inspection.jsonが存在する場合、その内容を読み込む\n",
    "    if os.path.exists(output_json_path):\n",
    "        with open(output_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            visual_data = json.load(f)\n",
    "    else:\n",
    "        visual_data = {}\n",
    "\n",
    "    extensions = ['.png', '.jpg', '.jpeg', '.JPG']\n",
    "\n",
    "    # ['data']からキーを順に読み込む\n",
    "    for key in data.keys():\n",
    "        parent_folder, child_folder, image_name = key.split(\"+\")\n",
    "        \n",
    "        # 各拡張子を試して、存在するファイルを見つける\n",
    "        for ext in extensions:\n",
    "            img_path = os.path.join(base_folder, parent_folder, child_folder, image_name + ext)\n",
    "            if os.path.exists(img_path):\n",
    "                # 画像をURL-safeなBase64 PNG形式に変換\n",
    "                visual_data[key] = image_to_urlsafe_base64_png(img_path)\n",
    "                break\n",
    "\n",
    "    # JSONをファイルに書き出し\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(visual_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "\"\"\" train \"\"\"\n",
    "input_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/train_images.json\"\n",
    "context_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, context_folder, output_json_path)\n",
    "query_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_query\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, query_folder, output_json_path)\n",
    "\n",
    "\"\"\" val \"\"\"\n",
    "input_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/val_images.json\"\n",
    "context_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, context_folder, output_json_path)\n",
    "query_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_query\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, query_folder, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "画像枚数: 14843\n",
      "val\n",
      "画像枚数: 2848\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 数の確認\n",
    "def count_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    count = len(data.keys())\n",
    "    print(f\"画像枚数: {count}\")\n",
    "    \n",
    "print(\"train\")\n",
    "json_path = f\"{base_folder}/train_images.json\"\n",
    "count_data(json_path)\n",
    "\n",
    "print(\"val\")\n",
    "json_path = f\"{base_folder}/val_images.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# icl_various_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/data/dataset/yyama_dataset/tasks/VI_ICL/various\"  # jsonファイルを保存するベースフォルダのパス\n",
    "os.makedirs(base_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "context_path = \"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\"\n",
    "generate_json_from_directory(context_path, output_json_path)\n",
    "\n",
    "output_json_path = f\"{base_folder}//val_instructions.json\"\n",
    "context_path = \"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\"\n",
    "generate_json_from_directory(context_path, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "画像枚数: 1\n",
      "val\n",
      "画像枚数: 1\n"
     ]
    }
   ],
   "source": [
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "query_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_query\"\n",
    "NUM = 5 # 良品、不良品をそれぞれ5枚ずつ選ぶ\n",
    "generate_and_merge_json_from_directory(query_path, output_json_path, NUM)\n",
    "\n",
    "output_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "query_path = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_query\"\n",
    "NUM = 5 # 良品、不良品をそれぞれ5枚ずつ選ぶ\n",
    "generate_and_merge_json_from_directory(query_path, output_json_path, NUM)\n",
    "\n",
    "print(\"train\")\n",
    "json_path = f\"{base_folder}/train_instructions.json\"\n",
    "count_data(json_path)\n",
    "\n",
    "print(\"val\")\n",
    "json_path = f\"{base_folder}/val_instructions.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_lines = [\n",
    "    [\"In the <image> provided, can you identify any apparent defects such as {defect} on this {product}?\"],\n",
    "    [\"Regarding the <image>, does this {product} exhibit any noticeable issues, for example, {defect}?\"],\n",
    "    [\"Looking at the <image>, are there discernible problems like {defect} present on the {product}?\"],\n",
    "    [\"Upon examining the <image>, are defects such as {defect} visible on this {product}?\"],\n",
    "    [\"Can any {defect}-type anomalies be spotted on the {product} in the <image>?\"],\n",
    "    [\"In this <image>, do you see any faults, specifically like {defect}, on the {product}?\"],\n",
    "    [\"Are imperfections, particularly {defect}, observable on the {product} in the <image>?\"],\n",
    "    [\"Does the <image> reveal any {defect} or similar flaws on the {product}?\"],\n",
    "    [\"Upon inspecting the <image>, are there any {defect} defects noticeable on the {product}?\"],\n",
    "    [\"Can one notice any {defect}-like issues in the {product} as depicted in the <image>?\"],\n",
    "    [\"Is there any evidence of {defect} or related faults on the {product} in the <image>?\"],\n",
    "    [\"Does this {product}, as shown in the <image>, have any visible anomalies, particularly {defect}?\"],\n",
    "    [\"Can you point out any visible {defect} faults in the {product} in the provided <image>?\"],\n",
    "    [\"Are there signs of {defect} or similar problems on the {product} shown in the <image>?\"],\n",
    "    [\"Regarding the <image> of the {product}, are there any noticeable {defect}-type faults?\"],\n",
    "    [\"In the <image>, do you detect any faults such as {defect} on this {product}?\"],\n",
    "    [\"Does the {product} in the <image> exhibit any {defect} or comparable defects?\"],\n",
    "    [\"Looking at this {product} in the <image>, are faults like {defect} visible?\"],\n",
    "    [\"Can any faults, particularly of the {defect} variety, be seen on the {product} in the <image>?\"],\n",
    "    [\"In the <image> shown, are there any detectable {defect}-like flaws on the {product}?\"],\n",
    "]\n",
    "\n",
    "yes_responses_array = [\n",
    "    [\"Yes. The {product} definitely shows {defect}.\"],\n",
    "    [\"Yes. A clear indication of {defect} on this {product} suggests it's defective.\"],\n",
    "    [\"Yes. Signs of {defect} are evident in the {product}, indicating a problem.\"],\n",
    "    [\"Yes. This {product} has {defect}, a clear defect.\"],\n",
    "    [\"Yes. Unmistakably, the {product} shows {defect}, pointing to a defect.\"],\n",
    "    [\"Yes. {defect} in the {product} is obvious, indicating a significant defect.\"],\n",
    "    [\"Yes. Considering the {product}, the presence of {defect} suggests it's not in perfect condition.\"],\n",
    "    [\"Yes. {defect} is noticeable on the {product}, indicating it's not as it should be.\"],\n",
    "    [\"Yes. With {defect} present, this {product} certainly seems defective.\"],\n",
    "    [\"Yes. {defect} on this {product} clearly points to a problem.\"],\n",
    "    [\"Yes. Upon a thorough examination of the {product}, it is quite apparent that there are significant signs of {defect}. This observation is critical as it strongly suggests that the product has a manufacturing or usage defect, which could potentially impact its functionality or aesthetic appeal.\"],\n",
    "    [\"Yes. After carefully analyzing the {product}, it's clear that there are unmistakable indications of {defect}. This is a cause for concern as it not only affects the integrity of the product but also raises questions about its longevity and reliability in the long term.\"],\n",
    "    [\"Yes. The presence of {defect} on this particular {product} is undeniable. This kind of flaw is not just superficial but could potentially signify deeper issues within the product, affecting its overall performance and customer satisfaction.\"],\n",
    "    [\"Yes. The {product} in question undeniably shows signs of {defect}. This finding is significant because it not only diminishes the product's aesthetic value but also suggests a compromise in the quality control processes of its manufacturing.\"],\n",
    "    [\"Yes. After an in-depth review, it's evident that the {product} exhibits {defect}. This is particularly concerning as it may indicate a lapse in the manufacturing standards or possibly mishandling during shipping or storage.\"],\n",
    "    [\"Yes. The {product} clearly displays {defect}, which is a red flag for potential buyers. Such defects are not just minor issues but could lead to further complications, possibly affecting the product's usability and customer satisfaction.\"],\n",
    "    [\"Yes. There is a noticeable presence of {defect} on the {product}, which is alarming. This type of defect could have various implications, ranging from aesthetic damage to potential functional impairments, depending on the severity and nature of the flaw.\"],\n",
    "    [\"Yes. This {product} unmistakably shows signs of {defect}, which is a significant concern. Defects of this nature are often indicative of deeper problems and could hint at a broader issue with the product line or brand quality.\"],\n",
    "    [\"Yes. After a detailed inspection, the {product} has visible {defect}, and this cannot be overlooked. Such defects raise serious questions about the product's durability and the reliability of the manufacturer's quality assurance processes.\"],\n",
    "    [\"Yes. It's unmistakably clear that the {product} has {defect}. This finding is critical as it not only impacts the immediate usability of the product but also raises concerns about its long-term durability and the trustworthiness of the brand.\"],\n",
    "]\n",
    "\n",
    "no_responses_array = [\n",
    "    [\"No. This {product} seems fine.\"],\n",
    "    [\"No. No visible faults like {defect} on the {product}.\"],\n",
    "    [\"No. {product} appears free of issues such as {defect}.\"],\n",
    "    [\"No. No {defect} faults detected on the {product}.\"],\n",
    "    [\"No. After checking, the {product} seems clear of {defect} issues.\"],\n",
    "    [\"No. {product} lacks any visible {defect} faults, indicating good condition.\"],\n",
    "    [\"No. Nothing like {defect} found on this {product}.\"],\n",
    "    [\"No. {product} looks good, no {defect} defects seen.\"],\n",
    "    [\"No. {product} appears non-defective, lacking {defect} type faults.\"],\n",
    "    [\"No. This {product} displays no {defect} issues, suggesting it's in prime condition.\"],\n",
    "    [\"No. After a comprehensive examination of the {product}, it appears to be free of any visible faults like {defect}. This observation is significant as it speaks volumes about the product's quality and the rigorous standards employed in its manufacturing process, ensuring that it is in a non-defective, pristine condition.\"],\n",
    "    [\"No. The {product} does not show any signs of faults such as {defect}. This is a testament to the high-quality materials and craftsmanship that have gone into its creation, ensuring that the product not only meets but exceeds the expectations of durability and aesthetic appeal.\"],\n",
    "    [\"No. Upon detailed scrutiny, there are no indications of faults like {defect} on the {product}. This finding is important as it suggests that the product has been manufactured with precision and care, maintaining a high standard of quality control.\"],\n",
    "    [\"No. The {product} seems to be in impeccable condition, displaying no visible faults like {defect}. This is reassuring as it indicates that the product has been handled and stored with utmost care, preserving its quality and integrity.\"],\n",
    "    [\"No. After a thorough inspection, the {product} does not exhibit any faults such as {defect}. This is a clear indicator of the product's superior quality and the meticulous attention to detail that has gone into its manufacturing process.\"],\n",
    "    [\"No. There are no visible signs of any faults like {defect} on the {product}, suggesting it has been crafted to perfection. This lack of defects is a strong indication of the product's robustness and the stringent quality checks it has undergone.\"],\n",
    "    [\"No. The {product} is devoid of any visible faults, including those like {defect}. This is a significant point, as it not only demonstrates the product's aesthetic perfection but also its functional reliability, which is a crucial aspect for consumer satisfaction.\"],\n",
    "    [\"No. Upon careful observation, the {product} displays no faults of the {defect} kind. This suggests that the product has passed through rigorous quality assessments, ensuring that it is in top-notch condition for the end-user.\"],\n",
    "    [\"No. The {product} is in a non-defective state, showing no signs of faults such as {defect}. This lack of defects is commendable and reflects the high standards of quality and care taken in the product's design and manufacturing process.\"],\n",
    "    [\"No. There are no discernible faults like {defect} on the {product}, which is a clear indicator of its exceptional quality. This flawless condition underscores the manufacturer's commitment to delivering a product that is not only visually appealing but also structurally sound and reliable.\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定されたリスト形式の文字列を作成する関数\n",
    "def generate_list_string(items):\n",
    "    # アンダースコアをスペースに変換\n",
    "    items = [item.replace('_', ' ') for item in items]\n",
    "    \n",
    "    if len(items) == 1:\n",
    "        return items[0]\n",
    "    elif len(items) == 2:\n",
    "        return f\"{items[0]} and {items[1]}\"\n",
    "    else:\n",
    "        return \", \".join(items[:-1]) + f\", and {items[-1]}\"\n",
    "\n",
    "def fill_instruction_and_answer(json_path, train_context_dir):\n",
    "    # JSONを読み込む\n",
    "    random_list = np.zeros(len(question_lines))\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    # ['data']からキーを順に読み込む\n",
    "    for key, value in data.items():\n",
    "        # キーの名前から親フォルダ名と子フォルダ名を認識する\n",
    "        parent_folder, child_folder, _ = key.split(\"+\")\n",
    "\n",
    "        # \"./1_train_context/親フォルダ名\"にアクセスし、その中にある子フォルダ名をリスト化する\n",
    "        subfolder_list = os.listdir(os.path.join(train_context_dir, parent_folder))\n",
    "        subfolder_list = [folder for folder in subfolder_list if folder != \"None\"] # 欠陥名のみリスト化\n",
    "\n",
    "        # \"instruction\"にテキストを入力する\n",
    "        parent_folder__ = parent_folder.replace('_', ' ')\n",
    "        # long\n",
    "        random_idx = random.randint(0, len(question_lines)-1)\n",
    "        random_list[random_idx] += 1\n",
    "        instructions = []\n",
    "        for q in question_lines:\n",
    "            instructions.append(q[0].format(product=parent_folder, defect=child_folder))\n",
    "        value[\"instruction\"] = instructions\n",
    "        \n",
    "        # \"answer\"にテキストを入力する\n",
    "        if child_folder == \"None\": # \"欠陥\"の場合\n",
    "        # if child_folder == parent_folder: # \"製品+欠陥\"の場合\n",
    "            answers = []\n",
    "            for no in no_responses_array:\n",
    "                answers.append(no[0].format(product=parent_folder, defect=child_folder))\n",
    "            value[\"answer\"] = answers\n",
    "        else:\n",
    "            child_folder = child_folder.replace('_', ' ')\n",
    "            answers = []\n",
    "            for yes in yes_responses_array:\n",
    "                answers.append(yes[0].format(product=parent_folder, defect=child_folder))\n",
    "            value[\"answer\"] = answers\n",
    "\n",
    "    # JSONをファイルに書き出し\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump({\"data\": data}, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# プログラムの実行\n",
    "output_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "train_context_dir = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\" # コンテキストのみでok (クエリと同じフォルダ構成のため)\n",
    "fill_instruction_and_answer(output_json_path, train_context_dir)\n",
    "\n",
    "output_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "train_context_dir = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\" # コンテキストのみでok (クエリと同じフォルダ構成のため)\n",
    "fill_instruction_and_answer(output_json_path, train_context_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "画像枚数: 138963\n",
      "val\n",
      "画像枚数: 1556\n"
     ]
    }
   ],
   "source": [
    "NUM_PAIRS = 25 # 1つのクエリに対して生成する組み合わせの数\n",
    "input_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/train_pairs{NUM_PAIRS}_train.json\"\n",
    "create_visual_inspection_train(input_json_path, output_json_path, NUM_PAIRS)\n",
    "\n",
    "NUM_PAIRS__ = 1 # 1つのクエリに対して生成する組み合わせの数（valは1にするとクエリが一回のみ）\n",
    "input_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/val_pairs{NUM_PAIRS__}_train.json\"\n",
    "create_visual_inspection_train(input_json_path, output_json_path, NUM_PAIRS__)\n",
    "\n",
    "print(\"train\")\n",
    "# NUM_PAIRS = 25\n",
    "json_path = f\"{base_folder}/train_pairs{NUM_PAIRS}_train.json\"\n",
    "count_data(json_path)\n",
    "print(\"val\")\n",
    "# NUM_PAIRS__ = 1\n",
    "json_path = f\"{base_folder}/val_pairs{NUM_PAIRS__}_train.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "画像枚数: 14843\n",
      "val\n",
      "画像枚数: 2848\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train \"\"\"\n",
    "input_json_path = f\"{base_folder}/train_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/train_images.json\"\n",
    "context_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_context\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, context_folder, output_json_path)\n",
    "query_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_train_query\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, query_folder, output_json_path)\n",
    "\n",
    "\"\"\" val \"\"\"\n",
    "input_json_path = f\"{base_folder}/val_instructions.json\"\n",
    "output_json_path = f\"{base_folder}/val_images.json\"\n",
    "context_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_context\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, context_folder, output_json_path)\n",
    "query_folder = f\"/data/dataset/yyama_dataset/VI_images/VI_full_val_query\"  # 画像読み込み用\n",
    "create_visual_inspection(input_json_path, query_folder, output_json_path)\n",
    "\n",
    "print(\"train\")\n",
    "json_path = f\"{base_folder}/train_images.json\"\n",
    "count_data(json_path)\n",
    "\n",
    "print(\"val\")\n",
    "json_path = f\"{base_folder}/val_images.json\"\n",
    "count_data(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
